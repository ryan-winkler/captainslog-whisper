# ðŸ–– Captain's Log

**Turn your voice into text â€” privately, on your own computer.**

No cloud services. No accounts. No data ever leaves your machine.

Hit record, talk, get text. That's it.

![Captain's Log UI](docs/screenshot.png)

---

## Quick Install

### One-line install (Linux/macOS)

```bash
curl -fsSL https://raw.githubusercontent.com/ryan-winkler/captainslog-whisper/main/install.sh | bash
```

This downloads, builds, and installs everything. It'll guide you through each step.

> **Prerequisite:** You need [Go](https://go.dev/dl/) installed first. The installer will tell you if it's missing.

### Manual install (3 steps)

<details>
<summary>Click to expand manual instructions</summary>

**Step 1: Start a transcription engine**

Captain's Log uses [Whisper](https://github.com/openai/whisper) (an open-source speech recognition model) to turn your voice into text. You need to run it separately:

```bash
# If you have Docker installed:
docker run -d -p 5000:5000 ghcr.io/heimoshuiyu/whisper-fastapi:latest

# Have a GPU? Add --gpus all for much faster transcription:
docker run -d -p 5000:5000 --gpus all ghcr.io/heimoshuiyu/whisper-fastapi:latest
```

> **No Docker?** You can also install it with pip:
> ```bash
> pip install faster-whisper fastapi uvicorn
> uvicorn whisper_fastapi:app --host 0.0.0.0 --port 5000
> ```

**Step 2: Build Captain's Log**

```bash
git clone https://github.com/ryan-winkler/captainslog-whisper.git
cd captainslog-whisper
go build -o captainslog ./cmd/captainslog
```

> **Need Go?** Download from [go.dev/dl](https://go.dev/dl/) â€” it's one file, no complicated setup.

**Step 3: Run it**

```bash
./captainslog
```

Open **http://localhost:8090** in your browser. Hit the mic button and talk. That's it.

</details>

### Start on boot

```bash
cp captainslog ~/.local/bin/
cp examples/captainslog.service ~/.config/systemd/user/
systemctl --user enable --now captainslog
```

---

## Using a Remote Whisper Server

Captain's Log doesn't need Whisper running on the same computer. If you have a more powerful machine (a VM, VPS, home server, etc.), you can point Captain's Log at it.

### Setup

1. Run Whisper on the remote machine:
   ```bash
   # On your GPU server / VPS / VM:
   docker run -d -p 5000:5000 --gpus all ghcr.io/heimoshuiyu/whisper-fastapi:latest
   ```

2. Tell Captain's Log where to find it â€” pick any method:

   **Option A: Settings UI** (easiest)
   Open Captain's Log â†’ click âš™ï¸ Preferences â†’ set **Whisper server URL** to your remote address (e.g. `http://192.168.1.100:5000`)

   **Option B: Environment variable**
   ```bash
   export CAPTAINSLOG_WHISPER_URL=http://192.168.1.100:5000
   ```

   **Option C: systemd service**
   ```bash
   systemctl --user edit captainslog
   # Add: Environment=CAPTAINSLOG_WHISPER_URL=http://your-server:5000
   ```

3. Verify the connection:
   ```bash
   curl http://your-server:5000/v1/models
   ```

### Examples

| Setup | Whisper URL |
|---|---|
| Same computer | `http://127.0.0.1:5000` (default) |
| Another PC on your network | `http://192.168.1.100:5000` |
| A VPS with a GPU | `http://gpu-server.example.com:5000` |
| Docker on a NAS | `http://nas.local:5000` |

> **Tip:** For remote servers, consider putting a reverse proxy (like Caddy or nginx) in front of Whisper with HTTPS.

---

## What Can It Do?

| Feature | What it means |
|---|---|
| ðŸŽ™ï¸ **Record & transcribe** | Click the mic, talk, get text |
| ðŸ“ **File upload** | Drag-and-drop audio or video files |
| ðŸ“‹ **Copy to clipboard** | Transcribed text is automatically copied |
| ðŸ’¾ **Save to PKM** | Auto-save to [Obsidian](https://obsidian.md/), [Logseq](https://logseq.com/), or any folder |
| ðŸ“¦ **Batch processing** | Drop multiple audio files â€” processed sequentially with progress |
| ðŸ” **Search history** | Instantly filter past transcriptions by text |
| ðŸ“Œ **Pin entries** | Star important transcriptions to keep them at the top |
| ðŸ¤– **Send to AI** | Clean up your dictation with a local LLM (Ollama, LM Studio) â€” proxied through Captain's Log (no CORS) |
| ðŸ“‚ **Go to file** | Open audio, text, or settings folders directly from the UI |
| â˜‘ï¸ **Bulk actions** | Select multiple entries to copy or save at once |
| ðŸŽ›ï¸ **Audio sources** | Pick your mic, system audio, mixer, or OBS |
| ðŸ“œ **Configurable history** | Set how many past transcriptions to show (default: 5) |
| ðŸ“¥ **Export** | One-click export using your default format, or **Export Asâ€¦** to pick `.txt`, `.md`, `.srt`, or `.vtt` |
| â±ï¸ **Real timestamps** | SRT/VTT exports include accurate timestamps from the Whisper backend |
| âŒ¨ï¸ **Keyboard shortcuts** | Space to record, M to toggle mini mode, and more |
| ðŸ“± **Mini mode** | Compact widget view â€” press `M` or add `?mini` to the URL |
| ðŸ”´ **Live streaming** | Real-time transcription via WebSocket (experimental) |
| ðŸ”’ **Private** | Everything stays on your machine |

---

## Settings

Click âš™ï¸ in the top-right corner to open Preferences. Everything is saved automatically.

#### ðŸ“ Storage

| Setting | What it does |
|---|---|
| **Save directory** | Where transcriptions are saved as markdown â€” works with Obsidian, Logseq, or any folder. Click ðŸ“‚ to open. |
| **Download directory** | Where exported files are downloaded. Click ðŸ“‚ to open. |
| **Recordings directory** | Where audio recordings are stored (read-only). Click ðŸ“‚ to open. |
| **Date format** | How dates appear in file names (ISO, EU, US, with day, named) |
| **File title** | Prefix for saved markdown files (default: "Dictation") |

#### ðŸŽ™ï¸ Transcription

| Setting | What it does |
|---|---|
| **Default language** | What language you're speaking â€” English, auto-detect, Gaeilge, PortuguÃªs, EspaÃ±ol, FranÃ§ais, Deutsch |
| **Initial prompt** | Guide the model with names, jargon, or context (e.g. "Meeting about warp core calibration") |
| **Whisper model** | Model size â€” large-v3 (best), medium (balanced), small (fast), base, tiny |
| **Skip silence (VAD)** | Automatically skip quiet parts to speed up processing |
| **Speaker labels** | Tag who said what (requires WhisperX or diarization-capable backend) |

#### âš¡ Behaviour

| Setting | What it does |
|---|---|
| **Auto-copy** | Automatically copy transcribed text to your clipboard |
| **Auto-save** | Automatically save every transcription to your save directory |
| **Show stardates** | Fun Star Trek stardate display (toggle on/off) |
| **Time format** | 12-hour (AM/PM), 24-hour, or system default |
| **History limit** | How many recent transcriptions to show (default: 5, 0 = unlimited) |
| **Default export format** | Format used by the Export button â€” Text, Markdown, SRT, or WebVTT |

#### ðŸ”Œ Connections

| Setting | What it does |
|---|---|
| **Port** | HTTP port Captain's Log listens on (read-only, change requires restart) |
| **Whisper backend URL** | Where the speech-to-text server is running (default: `http://127.0.0.1:5000`) |
| **Enable TLS** | Auto-generate self-signed certs for HTTPS/LAN access |
| **Enable Local LLM** | Connect to a local AI for post-processing â€” summarize, rewrite, extract action items |
| **Local LLM URL** | Where your AI is running (see [AI Post-Processing](#ai-post-processing) below) |
| **Local LLM Model** | Which AI model to use â€” pick from those installed in Ollama/LM Studio |

#### ðŸ“Š Observability

| Setting | What it does |
|---|---|
| **Access logging** | Log every HTTP request to stdout in JSON (off by default) |

### Keyboard shortcuts

| Key | Action |
|---|---|
| `Space` | Start/stop recording |
| `Ctrl+C` | Copy transcription |
| `Ctrl+S` | Save transcription |
| `M` | Toggle mini/full mode |
| `,` | Open preferences |
| `Escape` | Close preferences |

---

## Command-Line Options

You can pass options when starting Captain's Log to override the defaults. These override environment variables and settings.

```bash
# Start on a different port
captainslog --port 9090

# Point to a remote Whisper server
captainslog --whisper-url http://gpu-server:5000

# Set your Obsidian vault path
captainslog --vault ~/Documents/Vault/Dictation

# Check your version
captainslog --version
```

| Flag | What it does | Default |
|---|---|---|
| `--port` | Server port | 8090 |
| `--host` | Bind address | 0.0.0.0 |
| `--whisper-url` | Whisper backend URL | http://127.0.0.1:5000 |
| `--llm-url` | LLM server URL | http://127.0.0.1:11434 |
| `--vault` | Save directory for autosave | *(empty)* |
| `--history-limit` | Max history entries shown | 5 |
| `--enable-llm` | Enable local LLM integration | false |
| `--enable-tls` | Enable auto-TLS for HTTPS | false |
| `--stream-url` | WebSocket URL for live streaming | *(empty)* |
| `--version` | Print version and exit | â€” |

> **Terminal tip:** Captain's Log works great in [Ghostty](https://ghostty.org/), [Kitty](https://sw.kovidgoyal.net/kitty/), [Alacritty](https://alacritty.org/), or any terminal. Just run `captainslog` from your shell (zsh, bash, fish).

### Mini mode

A compact, minimal view showing only the record button and latest transcription. Great for a small window or sidebar.

- **Keyboard:** Press `M` to toggle between mini and full mode
- **URL:** Add `?mini` to the address: `http://localhost:8090/?mini`
- **Automatic:** The interface automatically switches to mini layout on narrow screens (under 520px)

> **Tip:** Drag the browser window to your preferred size and bookmark it. Mini mode is perfect as a floating widget while you work.

---

## AI Post-Processing

Captain's Log can send your transcriptions to a **local AI** running on your own computer for cleanup, formatting, or summarization. Think of it like having a personal editor that fixes typos and adds punctuation â€” but it runs entirely on your machine, so nothing leaves your network.

### How it works

1. You record something and get a transcription
2. You click the **ðŸ¤– Send to AI** button below your transcription
3. Captain's Log proxies the text through its own backend to your local AI (Ollama/LM Studio), avoiding browser CORS restrictions
4. The AI response appears directly below your transcription

> **Why a proxy?** Browsers block direct requests to `localhost:11434` due to [CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS). Captain's Log handles this by routing LLM requests through `/api/llm/chat` on the Go backend â€” same machine, no CORS, no data ever leaves your network.

### Setting it up

You need an AI running locally. Two popular options:

| App | What it is | URL to use in Preferences |
|---|---|---|
| [Ollama](https://ollama.com) | Command-line AI runner | `http://127.0.0.1:11434` |
| [LM Studio](https://lmstudio.ai) | Desktop app with a nice UI | `http://127.0.0.1:1234/v1` |

**Steps:**
1. Install Ollama or LM Studio and download a model (e.g. `llama3.2`)
2. Open Captain's Log â†’ âš™ï¸ Preferences â†’ Connections
3. Turn on **"Enable Local LLM"**
4. Paste the URL from the table above into **"Local LLM URL"**
5. Click the **â†» refresh button** next to the model dropdown â€” your models will appear
6. Pick a model and hit **"Save preferences"**

That's it. The ðŸ¤– **Send to AI** button will now appear in the action bar.

> **Any OpenAI-compatible API works** â€” if your AI app has a `/v1/chat/completions` endpoint, Captain's Log can talk to it. The full request body (model, messages, temperature, etc.) is forwarded transparently.

### Agent integration

Captain's Log works with [OpenClaw](https://github.com/openclaw/openclaw), [ZeroClaw](https://github.com/zeroclaw-labs/zeroclaw), and any agent that can run shell commands or HTTP requests. The LLM proxy at `/api/llm/chat` accepts the standard OpenAI chat completions format, so agents can post-process transcriptions without CORS issues.

```bash
# Agent can transcribe + post-process in one pipeline:
captainslog-cli transcribe meeting.mp3 | \
  curl -s -X POST http://localhost:8090/api/llm/chat \
    -H 'Content-Type: application/json' \
    -d '{"model":"llama3.2","messages":[{"role":"user","content":"Summarize: ..."}]}'
```

---

## Troubleshooting

### "Backend unreachable"

The transcription engine isn't running. Start it:

```bash
docker run -d -p 5000:5000 ghcr.io/heimoshuiyu/whisper-fastapi:latest
```

Or if it's on a remote machine, check that the URL in Preferences â†’ Whisper server URL is correct.

### No sound / mic not working

- Your browser needs permission to use the microphone
- On HTTP, this only works on `localhost` â€” if accessing from another device, enable TLS
- Check the audio source dropdown (next to the mic button) â€” make sure the right input is selected

### Transcription is slow

Transcription speed depends on three things: **model size**, **hardware**, and **settings**.

#### Quick wins (settings you can change right now)

| Setting | Recommendation | Why |
|---|---|---|
| **Beam size** | `5` (default) | Higher â‰  better. `10` is 2Ã— slower with negligible quality gain. |
| **Skip silence (VAD)** | **Enable** | Skips quiet parts â€” huge speedup for recordings with pauses |
| **Speaker labels (diarize)** | Disable when not needed | Expensive post-processing pass |
| **Word timestamps** | Disable when not needed | Extra alignment pass after transcription |
| **Model** | `large-v3-turbo` | **8Ã— faster** than `large-v3` with minimal quality loss |

#### Model comparison (CPU, int8)

| Model | Speed | Quality | Best for |
|---|---|---|---|
| `large-v3` | Slowest | Best | Final/archival transcriptions |
| `large-v3-turbo` | **8Ã— faster** | Near-v3 | â­ Recommended default |
| `distil-large-v3` | 2Ã— faster | Good | English-only use |
| `medium` | 4Ã— faster | Good | Low-end hardware |
| `small` | 8Ã— faster | OK | Quick drafts |
| `base` / `tiny` | Instant | Basic | Real-time / low-power |

#### AMD GPU acceleration

**If you have an AMD GPU** (like the RX 7900 XTX), `faster-whisper` / CTranslate2 **cannot use it** â€” they only support NVIDIA CUDA. However, **whisper.cpp supports AMD GPUs** via ROCm:

```bash
# Build whisper.cpp with ROCm (HIPBLAS) support
git clone https://github.com/ggerganov/whisper.cpp
cd whisper.cpp
cmake -B build -DGGML_HIPBLAS=1
cmake --build build --config Release -j

# Download a model
./build/bin/whisper-cli --download-model large-v3-turbo

# Run the server (OpenAI-compatible API)
./build/bin/whisper-server \
  --model models/ggml-large-v3-turbo.bin \
  --host 0.0.0.0 --port 5000
```

> **Expected speedup:** ~7Ã— faster than CPU. The RX 7900 XTX (24GB VRAM) handles `large-v3` comfortably.

Then point Captain's Log at it â€” same URL, same API:
```
Preferences â†’ Connections â†’ Whisper backend URL â†’ http://127.0.0.1:5000
```

#### NVIDIA GPU acceleration

```bash
# Docker (fastest setup)
docker run -d -p 5000:5000 --gpus all ghcr.io/heimoshuiyu/whisper-fastapi:latest

# Or pip
pip install faster-whisper
# faster-whisper automatically uses CUDA when available
```

### Built-in diagnostics

```bash
# Quick health check
curl http://localhost:8090/healthz?diag | python3 -m json.tool

# Or from the CLI
captainslog-cli diagnose
```

---

## For Developers

<details>
<summary>Click to expand technical details</summary>

### How it works

```
Browser / CLI / API
        â†“
Captain's Log (Go, port 8090)
        â†“
faster-whisper (port 5000)
        â†“
   Transcription
        â†“
Clipboard Â· Vault Â· AI forwarding
```

Captain's Log is a **~10MB static Go binary** with zero external dependencies. It proxies audio to [faster-whisper](https://github.com/SYSTRAN/faster-whisper) via [whisper-fastapi](https://github.com/heimoshuiyu/whisper-fastapi) and provides a browser UI, CLI, and [OpenAI-compatible API](https://platform.openai.com/docs/api-reference/audio).

### CLI

The CLI (`captainslog-cli`) is a pure bash + curl wrapper around the HTTP API. No external dependencies.

```bash
captainslog-cli transcribe meeting.mp3         # Transcribe a file â†’ stdout
captainslog-cli transcribe call.wav srt        # Transcribe as SRT (with timestamps)
captainslog-cli copy "text to clipboard"       # Copy to system clipboard (wl-copy/xclip/pbcopy)
captainslog-cli save "Notes from meeting"      # Save text to vault as markdown
captainslog-cli stardate                       # Print current stardate
captainslog-cli health                         # Check backend status
captainslog-cli models                         # List available Whisper/LLM models
captainslog-cli diagnose                       # Full self-diagnostic (server, whisper, vault, clipboard)
captainslog-cli settings                       # Show all settings as JSON
captainslog-cli settings language fr           # Update a single setting
captainslog-cli update                         # Pull latest + rebuild + install
captainslog-cli version                        # Print server version
```

Pipe-friendly:
```bash
captainslog-cli transcribe audio.mp3 | captainslog-cli copy   # Transcribe â†’ clipboard
captainslog-cli transcribe audio.mp3 | captainslog-cli save   # Transcribe â†’ vault
echo "dictated text" | captainslog-cli save                    # Pipe text â†’ vault
```

### API

| Endpoint | Method | Description |
|---|---|---|
| `/v1/audio/transcriptions` | `POST` | [OpenAI-compatible](https://platform.openai.com/docs/api-reference/audio/createTranscription) (multipart). JSON responses are enriched with SRT-parsed segments for real timestamps. |
| `/v1/audio/translations` | `POST` | Translate audio to English |
| `/api/llm/chat` | `POST` | LLM proxy â€” forwards OpenAI chat completions to Ollama/LM Studio (avoids CORS) |
| `/api/settings` | `GET`/`PUT` | Persistent settings (merged on PUT, full replace not required) |
| `/api/vault/save` | `POST` | Save text to vault as markdown (`{"text":"...","language":"en"}`) |
| `/api/recordings` | `POST` | Save audio recording (multipart) |
| `/api/open` | `POST` | Open file/folder in system file manager (`?path=...`) |
| `/api/models` | `GET` | Available Whisper + LLM models |
| `/api/config` | `GET` | Read-only runtime config (vault, llm, auth, tls status) |
| `/api/stardate` | `GET` | Current stardate |
| `/healthz` | `GET` | Health check (add `?diag` for detailed diagnostics) |

### Environment variables

For server-level config (systemd, Docker). Most users won't need these.

| Variable | Default | Description |
|---|---|---|
| `CAPTAINSLOG_PORT` | `8090` | HTTP port |
| `CAPTAINSLOG_HOST` | `0.0.0.0` | Bind address |
| `CAPTAINSLOG_WHISPER_URL` | `http://127.0.0.1:5000` | Whisper backend URL |
| `CAPTAINSLOG_LLM_URL` | `http://127.0.0.1:11434` | Local LLM URL (Ollama, LM Studio, etc.) |
| `CAPTAINSLOG_ENABLE_LLM` | `false` | Enable local LLM integration |
| `CAPTAINSLOG_AUTH_TOKEN` | *(empty)* | Bearer token for auth |
| `CAPTAINSLOG_VAULT_DIR` | *(empty)* | Obsidian vault path |
| `CAPTAINSLOG_CONFIG_DIR` | `~/.config/captainslog` | Settings location |
| `CAPTAINSLOG_ENABLE_TLS` | `false` | Auto-generate TLS cert |
| `CAPTAINSLOG_RATE_LIMIT` | `0` | Requests/minute (0 = disabled, set >0 for LAN/public) |
| `CAPTAINSLOG_HISTORY_LIMIT` | `5` | Max history entries shown |
| `CAPTAINSLOG_STREAM_URL` | *(empty)* | WebSocket URL for live streaming (e.g. `ws://localhost:8765`) |
| `CAPTAINSLOG_LOG_FORMAT` | `text` | Log format (`text` or `json`) |
| `CAPTAINSLOG_LOG_DIR` | *(empty)* | Log file directory (auto-rotated, stdout always active) |

> **Migrating from older versions?** `CAPTAINSLOG_OLLAMA_URL` and `CAPTAINSLOG_ENABLE_OLLAMA` still work â€” they're automatically mapped to the new names.

### ðŸ”´ Live Streaming (experimental)

Captain's Log can stream transcription **live** while you record, showing partial text in real time. This requires a separate streaming backend like [WhisperLiveKit](https://github.com/QuentinFuxa/WhisperLiveKit) or [whisper_streaming](https://github.com/ufal/whisper_streaming).

```bash
# Start a streaming backend (pick one)
pip install whisper-live-kit
whisper-live-kit --host 0.0.0.0 --port 8765

# Point Captain's Log to it
captainslog --stream-url ws://localhost:8765
# or: export CAPTAINSLOG_STREAM_URL=ws://localhost:8765
```

When a streaming URL is configured:
- A **LIVE** badge appears during recording
- Partial text appears in the Latest card as you speak
- On stop, final transcription is still saved to history + vault as normal
- If the streaming backend is unavailable, Captain's Log falls back to post-recording transcription automatically

### Docker

```bash
docker build -t captainslog .
docker run -p 8090:8090 \
  -e CAPTAINSLOG_WHISPER_URL=http://host.docker.internal:5000 \
  captainslog
```

### AI agent integration

Captain's Log works with [OpenClaw](https://github.com/openclaw/openclaw), [ZeroClaw](https://github.com/zeroclaw-labs/zeroclaw), and any agent that can run shell commands or HTTP requests. See the [OpenClaw skill](skills/captainslog/) or add to your agent's config:

```markdown
## Captain's Log (Speech-to-Text)
- CLI: `captainslog-cli transcribe <file>`, `captainslog-cli save "text"`
- API: POST http://127.0.0.1:8090/v1/audio/transcriptions (multipart, OpenAI-compatible)
- Health: GET http://127.0.0.1:8090/healthz
```

### Integrations

| Integration | How |
|---|---|
| [**faster-whisper**](https://github.com/SYSTRAN/faster-whisper) | Transcription engine (4x faster than OpenAI Whisper) |
| [**Ollama**](https://ollama.com/) | Post-processing: punctuation, summaries, filler removal |
| [**Obsidian**](https://obsidian.md/) | Daily markdown files with YAML frontmatter |
| [**Home Assistant**](https://www.home-assistant.io/) | Local voice via Wyoming protocol |

### Contributing

1. Fork â†’ Branch â†’ Commit â†’ PR
2. `go run ./cmd/captainslog` for dev server
3. `go test ./...` to run tests

**Code style**: Go stdlib only Â· vanilla HTML/CSS/JS Â· no external JS dependencies

</details>

---

## Stardates & Quirks

Captain's Log shows [TNG-era stardates](https://en.wikipedia.org/wiki/Stardate) in the header (toggle in Preferences â†’ Show stardates).

**How it works:** `-(year offset Ã— 1000) + day_fraction`. Negative stardates = we're still in the "past" relative to TNG.

**Quirks:**
- Stardates are aesthetic, not canon-accurate
- The waveform shows frequency bars (spectrum analyser), not raw audio
- History is in your browser's localStorage â€” clearing browser data removes it, but vault files on disk are safe

---

## Privacy & Permissions

Captain's Log needs microphone access from both your **browser** and your **operating system**. If recording doesn't work, check both levels:

### Browser permissions

When you first click Record, your browser will ask for microphone permission. Click **Allow**.

If you accidentally blocked it:
- **Chrome/Edge**: Click the ðŸ”’ icon in the address bar â†’ Site settings â†’ Microphone â†’ Allow
- **Firefox**: Click the ðŸ”’ icon â†’ Connection secure â†’ More information â†’ Permissions â†’ Microphone
- **Safari**: Safari â†’ Settings â†’ Websites â†’ Microphone â†’ Allow for this site

> **HTTPS note:** Chrome blocks microphone access on non-HTTPS sites (except `localhost`). If accessing Captain's Log over your LAN, either:
> 1. Set `CAPTAINSLOG_ENABLE_TLS=true` (auto-generates a self-signed cert)
> 2. Add `http://your-server:8090` to `chrome://flags/#unsafely-treat-insecure-origin-as-secure`

### macOS

**System Settings â†’ Privacy & Security â†’ Microphone** â†’ enable your browser (Chrome, Firefox, Safari, etc.)

If your browser isn't listed, open it and try recording â€” macOS will prompt you.

### Windows

**Settings â†’ Privacy & Security â†’ Microphone** â†’ ensure:
1. "Microphone access" is On
2. "Let apps access your microphone" is On
3. Your browser is listed and enabled under "Let desktop apps access your microphone"

### Linux

Most Linux desktops use PipeWire (or PulseAudio). Check:
- **GNOME**: Settings â†’ Sound â†’ Input â†’ verify your mic is selected
- **KDE Plasma**: System Settings â†’ Audio â†’ Input Devices â†’ verify your mic is active
- **PipeWire/PulseAudio**: `pactl list sources short` to see available inputs
- **Flatpak browsers**: May need portal permissions â€” run `flatpak permissions` or reinstall with `--device=all`

### Android

**Settings â†’ Apps â†’ [your browser] â†’ Permissions â†’ Microphone â†’ Allow**

Chrome on Android will also prompt when you first try to record.

### iOS / iPadOS

**Settings â†’ [your browser] â†’ Microphone â†’ On**

Safari requires HTTPS for microphone access on iOS (localhost doesn't bypass this on mobile).

### ChromeOS

**Settings â†’ Privacy and security â†’ Site settings â†’ Microphone** â†’ ensure Captain's Log is allowed.

---

## Troubleshooting

| Problem | Solution |
|---|---|
| **"Microphone access required"** | Check browser + OS permissions (see [Privacy & Permissions](#privacy--permissions)) |
| **"No microphone detected"** | Verify audio input device is connected and selected in OS sound settings |
| **Recording works but transcription fails** | Check Whisper is running: `curl http://localhost:5000/v1/models` |
| **"Backend unreachable"** | Start the Whisper server: `docker run -d -p 5000:5000 ghcr.io/heimoshuiyu/whisper-fastapi:latest` |
| **Slow transcription** | Enable VAD, reduce beam_size to 5, try `large-v3-turbo`. AMD GPU? Use [whisper.cpp with ROCm](#amd-gpu-acceleration). See [full guide](#transcription-is-slow). |
| **Rate limit error** | Disabled by default. If enabled, set `CAPTAINSLOG_RATE_LIMIT=0` to disable |
| **PWA won't install** | Must be on HTTPS or localhost. Try Chrome â†’ â‹® â†’ Install app |
| **Ctrl+S saves HTML page** | Update to latest version â€” this was fixed in v0.2.0 |
| **Can't hear playback** | Audio recordings are saved server-side. Click ðŸ”Š on a history entry to play. |
| **Settings not saving** | Check browser console (F12) for errors. Settings require the backend to be running. |

> **Still stuck?** Open an issue on [GitHub](https://github.com/ryan-winkler/captainslog-whisper/issues/new) with:
> 1. Your OS and browser
> 2. The output of `curl http://localhost:8090/healthz?diag`
> 3. Any errors from the browser console (F12 â†’ Console)

---

## Security

- **All audio processed locally** â€” never leaves your machine
- **No telemetry, analytics, or tracking** â€” zero external requests
- **No accounts or sign-up** â€” just run the binary
- **Optional auth token** (`CAPTAINSLOG_AUTH_TOKEN`) for LAN/remote access
- **Optional auto-TLS** (`CAPTAINSLOG_ENABLE_TLS`) generates a self-signed cert
- **Rate limiting** available for public-facing deployments (`CAPTAINSLOG_RATE_LIMIT`)
- **XSS-safe** â€” all user content is HTML-escaped before rendering
- **Content from external APIs** (Whisper responses) is sanitized before display

## Ecosystem & Integrations

Captain's Log uses standard APIs (OpenAI-compatible `/v1/audio/transcriptions`) and can work alongside many tools in the open-source speech ecosystem.

### Whisper Backends

| Backend | Best For | Setup |
|---|---|---|
| [whisper.cpp](https://github.com/ggerganov/whisper.cpp) | **AMD GPU (ROCm)**, low-memory, C++ | Build with `-DGGML_HIPBLAS=1`, run `whisper-server` |
| [CrisperWhisper](https://github.com/nyrahealth/CrisperWhisper) | **Precise word-level timestamps**, filler detection, #1 OpenASR | `nyrahealth/faster_CrisperWhisper` model with faster-whisper |
| [faster-whisper-server](https://github.com/fedirz/faster-whisper-server) | NVIDIA GPU, fast inference | `pip install faster-whisper-server && uvicorn ...` |
| [whisper-fastapi](https://github.com/heimoshuiyu/whisper-fastapi) | Home Assistant / webhook integration | Docker: `ghcr.io/heimoshuiyu/whisper-fastapi` |
| [SYSTRAN/faster-whisper](https://github.com/SYSTRAN/faster-whisper) | Library for custom backends | Python library â€” build your own API around it |

### Live Streaming

| Project | What it does |
|---|---|
| [whisper_streaming](https://github.com/ufal/whisper_streaming) | Real-time WebSocket transcription. Set `--stream-url ws://localhost:43007` |
| [OBS Live Translation](https://github.com/eddieoz/OBS-live-translation) | Capture OBS audio â†’ live captions. Route OBS output to Captain's Log via virtual mic |

### Post-Processing & Translation

| Project | What it does |
|---|---|
| [OpenLRC](https://github.com/zh-plus/openlrc) | Generate LRC lyrics files from audio. Use Captain's Log SRT export as input |
| [open-dubbing](https://github.com/softcatala/open-dubbing) | Dub audio into other languages. Feed Captain's Log SRT output as source subtitles |

### CLI Piping

Captain's Log transcriptions can be piped to any CLI tool:

```bash
# Send latest transcription to Gemini CLI
curl -s http://localhost:8090/api/settings | jq -r '.vault_dir' | \
  xargs -I{} cat "{}/$(date +%Y-%m-%d).md" | \
  gemini "Summarize the key points from these dictation notes"

# Or pipe directly to any LLM CLI
echo "Clean up this transcription:" | cat - /path/to/dictation.md | ollama run llama3.2
```

### Home Automation

- **Home Assistant**: Use [whisper-fastapi](https://github.com/heimoshuiyu/whisper-fastapi) as the Whisper backend, which has native HA integration
- **ZeroClaw**: Point ZeroClaw's speech input at `http://localhost:8090/v1/audio/transcriptions` â€” it's the same OpenAI-compatible API

---

## License

[PolyForm Small Business 1.0.0](LICENSE.md)

**Free for individuals and small businesses** (under 100 employees / $1M revenue). Larger organizations need a commercial license â€” contact [ryanw.eu](https://ryanw.eu).

---

> ðŸŒŸ **[Star this repo](https://github.com/ryan-winkler/captainslog-whisper)** to get notified about new releases, bug fixes, and features.

*Live long and transcribe.* ðŸ––
